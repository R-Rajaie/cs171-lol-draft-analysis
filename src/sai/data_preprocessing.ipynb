{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6da171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import os\n",
    "import gzip, json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a6b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "data_dir = os.path.join(curr_dir, \"..\", \"..\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94bc338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_match(data):\n",
    "    res = {}\n",
    "    for team in data['teams']:\n",
    "        res = res | {f\"{team['side'].upper()}_{participant['individualPosition']}\": participant['championName'] for participant in team['participants']}\n",
    "        res[\"RED_WINNER\"] = team['isWinner'] if team['side'] == 'red' else not team['isWinner']\n",
    "\n",
    "    return res\n",
    "\n",
    "STARTING_INDEX = 2\n",
    "END_INDEX = 14\n",
    "\n",
    "def build_dataset():\n",
    "    res = []\n",
    "    for i in range(STARTING_INDEX, END_INDEX):  # assuming you have 12 batches numbered from 2 to 13 in folder caled \"match_data\", which can be extracted from \"data_fetching.ipynb\"\n",
    "        print(\"Processing batch \", i)\n",
    "        with gzip.open(os.path.join(data_dir, \"sai_match_data\", f\"match_batch_{i}.json.gz\"), \"rt\", encoding=\"utf-8\") as f:\n",
    "            batched_data = json.load(f)\n",
    "            res.extend(preprocess_match(data) for data in batched_data)\n",
    "    return pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3808f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch  2\n",
      "Processing batch  3\n",
      "Processing batch  4\n",
      "Processing batch  5\n",
      "Processing batch  6\n",
      "Processing batch  7\n",
      "Processing batch  8\n",
      "Processing batch  9\n",
      "Processing batch  10\n",
      "Processing batch  11\n",
      "Processing batch  12\n",
      "Processing batch  13\n"
     ]
    }
   ],
   "source": [
    "df = build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1614012",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_dir, \"sai_preprocessed_data\",\"preprocessed_matches.csv\"), index=False)\n",
    "\n",
    "# I ran this already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a465b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs171",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
